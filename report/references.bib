

@article{zhuang_comprehensive_2021,
	title = {A {Comprehensive} {Survey} on {Transfer} {Learning}},
	volume = {109},
	issn = {0018-9219, 1558-2256},
	url = {https://ieeexplore.ieee.org/document/9134370/},
	doi = {10.1109/JPROC.2020.3004555},
	language = {en},
	number = {1},
	urldate = {2023-09-25},
	journal = {Proceedings of the IEEE},
	author = {Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
	month = jan,
	year = {2021},
	pages = {43--76},
	file = {Zhuang et al. - 2021 - A Comprehensive Survey on Transfer Learning.pdf:/home/gurp/Zotero/storage/JD3WYJKN/Zhuang et al. - 2021 - A Comprehensive Survey on Transfer Learning.pdf:application/pdf},
}

@misc{silvestrin_transfer-learning_2023,
	title = {Transfer-{Learning} {Across} {Datasets} with {Different} {Input} {Dimensions}: {An} {Algorithm} and {Analysis} for the {Linear} {Regression} {Case}},
	shorttitle = {Transfer-{Learning} {Across} {Datasets} with {Different} {Input} {Dimensions}},
	url = {http://arxiv.org/abs/2202.05069},
	abstract = {With the development of new sensors and monitoring devices, more sources of data become available to be used as inputs for machine learning models. These can on the one hand help to improve the accuracy of a model. On the other hand however, combining these new inputs with historical data remains a challenge that has not yet been studied in enough detail. In this work, we propose a transfer-learning algorithm that combines the new and the historical data, that is especially beneficial when the new data is scarce. We focus the approach on the linear regression case, which allows us to conduct a rigorous theoretical study on the benefits of the approach. We show that our approach is robust against negative transfer-learning, and we confirm this result empirically with real and simulated data.},
	urldate = {2023-09-27},
	publisher = {arXiv},
	author = {Silvestrin, Luis Pedro and van Zanten, Harry and Hoogendoorn, Mark and Koole, Ger},
	month = aug,
	year = {2023},
	note = {arXiv:2202.05069 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Code available at https://github.com/lpsilvestrin/incremental\_input\_tl},
	file = {arXiv.org Snapshot:/home/gurp/Zotero/storage/8HGHDBKL/2202.html:text/html;Full Text PDF:/home/gurp/Zotero/storage/C4BW8QVS/Silvestrin et al. - 2023 - Transfer-Learning Across Datasets with Different I.pdf:application/pdf},
}

@article{ye_implementing_2021,
	title = {Implementing transfer learning across different datasets for time series forecasting},
	volume = {109},
	issn = {00313203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320320304209},
	doi = {10.1016/j.patcog.2020.107617},
	language = {en},
	urldate = {2023-09-29},
	journal = {Pattern Recognition},
	author = {Ye, Rui and Dai, Qun},
	month = jan,
	year = {2021},
	pages = {107617},
	file = {Ye and Dai - 2021 - Implementing transfer learning across different da.pdf:/home/gurp/Zotero/storage/Z8NIGMXI/Ye and Dai - 2021 - Implementing transfer learning across different da.pdf:application/pdf},
}

@article{ye_novel_2018,
	title = {A novel transfer learning framework for time series forecasting},
	volume = {156},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S095070511830251X},
	doi = {10.1016/j.knosys.2018.05.021},
	language = {en},
	urldate = {2023-09-29},
	journal = {Knowledge-Based Systems},
	author = {Ye, Rui and Dai, Qun},
	month = sep,
	year = {2018},
	pages = {74--99},
	file = {Ye and Dai - 2018 - A novel transfer learning framework for time serie.pdf:/home/gurp/Zotero/storage/YS5DNRBD/Ye and Dai - 2018 - A novel transfer learning framework for time serie.pdf:application/pdf},
}

@article{day_survey_2017,
	title = {A survey on heterogeneous transfer learning},
	volume = {4},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-017-0089-0},
	doi = {10.1186/s40537-017-0089-0},
	abstract = {Transfer learning has been demonstrated to be effective for many real-world applications as it exploits knowledge present in labeled training data from a source domain to enhance a model’s performance in a target domain, which has little or no labeled target training data. Utilizing a labeled source, or auxiliary, domain for aiding a target task can greatly reduce the cost and effort of collecting sufficient training labels to create an effective model in the new target distribution. Currently, most transfer learning methods assume the source and target domains consist of the same feature spaces which greatly limits their applications. This is because it may be difficult to collect auxiliary labeled source domain data that shares the same feature space as the target domain. Recently, heterogeneous transfer learning methods have been developed to address such limitations. This, in effect, expands the application of transfer learning to many other real-world tasks such as cross-language text categorization, text-to-image classification, and many others. Heterogeneous transfer learning is characterized by the source and target domains having differing feature spaces, but may also be combined with other issues such as differing data distributions and label spaces. These can present significant challenges, as one must develop a method to bridge the feature spaces, data distributions, and other gaps which may be present in these cross-domain learning tasks. This paper contributes a comprehensive survey and analysis of current methods designed for performing heterogeneous transfer learning tasks to provide an updated, centralized outlook into current methodologies.},
	number = {1},
	urldate = {2023-11-11},
	journal = {Journal of Big Data},
	author = {Day, Oscar and Khoshgoftaar, Taghi M.},
	month = sep,
	year = {2017},
	keywords = {Heterogeneous transfer learning, Knowledge transfer, Semisupervised learning, Supervised learning, Transfer learning, Unsupervised learning},
	pages = {29},
	file = {Day and Khoshgoftaar - 2017 - A survey on heterogeneous transfer learning.pdf:/home/gurp/Zotero/storage/G7GGIREN/Day and Khoshgoftaar - 2017 - A survey on heterogeneous transfer learning.pdf:application/pdf},
}

@article{kim_effectiveness_2020,
	title = {Effectiveness of transfer learning for enhancing tumor classification with a convolutional neural network on frozen sections {\textbar} {Scientific} {Reports}},
	volume = {10},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-78129-0},
	doi = {10.1038/s41598-020-78129-0},
	abstract = {Fast and accurate confirmation of metastasis on the frozen tissue section of intraoperative sentinel lymph node biopsy is an essential tool for critical surgical decisions. However, accurate diagnosis by pathologists is difficult within the time limitations. Training a robust and accurate deep learning model is also difficult owing to the limited number of frozen datasets with high quality labels. To overcome these issues, we validated the effectiveness of transfer learning from CAMELYON16 to improve performance of the convolutional neural network (CNN)-based classification model on our frozen dataset (N = 297) from Asan Medical Center (AMC). Among the 297 whole slide images (WSIs), 157 and 40 WSIs were used to train deep learning models with different dataset ratios at 2, 4, 8, 20, 40, and 100\%. The remaining, i.e., 100 WSIs, were used to validate model performance in terms of patch- and slide-level classification. An additional 228 WSIs from Seoul National University Bundang Hospital (SNUBH) were used as an external validation. Three initial weights, i.e., scratch-based (random initialization), ImageNet-based, and CAMELYON16-based models were used to validate their effectiveness in external validation. In the patch-level classification results on the AMC dataset, CAMELYON16-based models trained with a small dataset (up to 40\%, i.e., 62 WSIs) showed a significantly higher area under the curve (AUC) of 0.929 than those of the scratch- and ImageNet-based models at 0.897 and 0.919, respectively, while CAMELYON16-based and ImageNet-based models trained with 100\% of the training dataset showed comparable AUCs at 0.944 and 0.943, respectively. For the external validation, CAMELYON16-based models showed higher AUCs than those of the scratch- and ImageNet-based models. Model performance for slide feasibility of the transfer learning to enhance model performance was validated in the case of frozen section datasets with limited numbers.},
	number = {1},
	urldate = {2023-11-11},
	journal = {Scientific Reports},
	author = {Kim, Young-Gon and Kim, Sungchul and Cho, Cristina Eunbee and Song, In Hye and Lee, Hee Jin and Ahn, Soomin and Park, So Yeon and Gong, Gyungyub and Kim, Namkug},
	month = dec,
	year = {2020},
	pages = {21899},
	file = {Kim et al. - 2020 - Effectiveness of transfer learning for enhancing tumor classification with a convolutional neural network on frozen sections  Scientific Reports.pdf:/home/gurp/Zotero/storage/6HNGTFID/Kim et al. - 2020 - Effectiveness of transfer learning for enhancing tumor classification with a convolutional neural network on frozen sections  Scientific Reports.pdf:application/pdf},
}

@misc{zhuang_transfer_2019,
	title = {Transfer {Learning} {Toolkit}: {Primers} and {Benchmarks}},
	shorttitle = {Transfer {Learning} {Toolkit}},
	url = {http://arxiv.org/abs/1911.08967},
	doi = {10.48550/arXiv.1911.08967},
	abstract = {The transfer learning toolkit wraps the codes of 17 transfer learning models and provides integrated interfaces, allowing users to use those models by calling a simple function. It is easy for primary researchers to use this toolkit and to choose proper models for real-world applications. The toolkit is written in Python and distributed under MIT open source license. In this paper, the current state of this toolkit is described and the necessary environment setting and usage are introduced.},
	urldate = {2023-11-11},
	publisher = {arXiv},
	author = {Zhuang, Fuzhen and Duan, Keyu and Guo, Tongjia and Zhu, Yongchun and Xi, Dongbo and Qi, Zhiyuan and He, Qing},
	month = nov,
	year = {2019},
	note = {arXiv:1911.08967 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: A Transfer Learning Toolkit},
	file = {arXiv Fulltext PDF:/home/gurp/Zotero/storage/L975XY4K/Zhuang et al. - 2019 - Transfer Learning Toolkit Primers and Benchmarks.pdf:application/pdf;arXiv.org Snapshot:/home/gurp/Zotero/storage/WMYY3I36/1911.html:text/html},
}

@article{pan_survey_2010,
	title = {A {Survey} on {Transfer} {Learning}},
	volume = {22},
	issn = {1558-2191},
	url = {https://ieeexplore.ieee.org/document/5288526},
	doi = {10.1109/TKDE.2009.191},
	abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
	number = {10},
	urldate = {2023-11-17},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Pan, Sinno Jialin and Yang, Qiang},
	month = oct,
	year = {2010},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	pages = {1345--1359},
	file = {ASurveyOnTransferLearningPanYang.pdf:/home/gurp/Zotero/storage/QVQA7ZYJ/transfer-learning.pdf:application/pdf;IEEE Xplore Abstract Record:/home/gurp/Zotero/storage/377ECAE2/5288526.html:text/html},
}

@article{weiss_survey_2016,
	title = {A survey of transfer learning},
	volume = {3},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-016-0043-6},
	doi = {10.1186/s40537-016-0043-6},
	abstract = {Machine learning and data mining techniques have been used in numerous real-world applications. An assumption of traditional machine learning methodologies is the training data and testing data are taken from the same domain, such that the input feature space and data distribution characteristics are the same. However, in some real-world machine learning scenarios, this assumption does not hold. There are cases where training data is expensive or difficult to collect. Therefore, there is a need to create high-performance learners trained with more easily obtained data from different domains. This methodology is referred to as transfer learning. This survey paper formally defines transfer learning, presents information on current solutions, and reviews applications applied to transfer learning. Lastly, there is information listed on software downloads for various transfer learning solutions and a discussion of possible future research work. The transfer learning solutions surveyed are independent of data size and can be applied to big data environments.},
	number = {1},
	urldate = {2023-11-17},
	journal = {Journal of Big Data},
	author = {Weiss, Karl and Khoshgoftaar, Taghi M. and Wang, DingDing},
	month = may,
	year = {2016},
	keywords = {Data mining, Domain adaptation, Machine learning, Survey, Transfer learning},
	pages = {9},
	file = {ASurveyOfTransferLearningWeiss.pdf:/home/gurp/Zotero/storage/T6VLJ2A3/s40537-016-0043-6.pdf:application/pdf;Snapshot:/home/gurp/Zotero/storage/4Y224EEA/s40537-016-0043-6.html:text/html},
}

@misc{weber_transfer_2021,
	title = {Transfer {Learning} {With} {Time} {Series} {Data}: {A} {Systematic} {Mapping} {Study}},
	url = {https://ieeexplore.ieee.org/document/9646532},
	urldate = {2023-11-17},
	journal = {IEEE Journals \& Magazine {\textbar} IEEE Xplore},
	author = {Weber, Manuel and Auch, Maximilian and Doblander, Christoph and Mandl, Peter and Jacobsen, Hans-Arno},
	year = {2021},
	file = {Transfer Learning With Time Series Data\: A Systematic Mapping Study | IEEE Journals & Magazine | IEEE Xplore:/home/gurp/Zotero/storage/DP795I7W/9646532.html:text/html;TransferLearningWithTimeseriesWeber.pdf:/home/gurp/Zotero/storage/4CHCD8WB/document.pdf:application/pdf},
}

@inproceedings{fawaz_transfer_2018,
	title = {Transfer learning for time series classification},
	url = {http://arxiv.org/abs/1811.01533},
	doi = {10.1109/BigData.2018.8621990},
	abstract = {Transfer learning for deep neural networks is the process of first training a base network on a source dataset, and then transferring the learned features (the network's weights) to a second network to be trained on a target dataset. This idea has been shown to improve deep neural network's generalization capabilities in many computer vision tasks such as image recognition and object localization. Apart from these applications, deep Convolutional Neural Networks (CNNs) have also recently gained popularity in the Time Series Classification (TSC) community. However, unlike for image recognition problems, transfer learning techniques have not yet been investigated thoroughly for the TSC task. This is surprising as the accuracy of deep learning models for TSC could potentially be improved if the model is fine-tuned from a pre-trained neural network instead of training it from scratch. In this paper, we fill this gap by investigating how to transfer deep CNNs for the TSC task. To evaluate the potential of transfer learning, we performed extensive experiments using the UCR archive which is the largest publicly available TSC benchmark containing 85 datasets. For each dataset in the archive, we pre-trained a model and then fine-tuned it on the other datasets resulting in 7140 different deep neural networks. These experiments revealed that transfer learning can improve or degrade the model's predictions depending on the dataset used for transfer. Therefore, in an effort to predict the best source dataset for a given target dataset, we propose a new method relying on Dynamic Time Warping to measure inter-datasets similarities. We describe how our method can guide the transfer to choose the best source dataset leading to an improvement in accuracy on 71 out of 85 datasets.},
	urldate = {2023-11-17},
	booktitle = {2018 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Fawaz, Hassan Ismail and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
	month = dec,
	year = {2018},
	note = {arXiv:1811.01533 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1367--1376},
	annote = {Comment: Accepted at IEEE International Conference on Big Data 2018},
	file = {arXiv.org Snapshot:/home/gurp/Zotero/storage/VK62743T/1811.html:text/html;Transfer learning for time series classification  FawazWeber.pdf:/home/gurp/Zotero/storage/WSJ7K5G5/1811.015331.pdf:application/pdf},
}

@misc{wen_time_2019,
	title = {Time {Series} {Anomaly} {Detection} {Using} {Convolutional} {Neural} {Networks} and {Transfer} {Learning}},
	url = {http://arxiv.org/abs/1905.13628},
	doi = {10.48550/arXiv.1905.13628},
	abstract = {Time series anomaly detection plays a critical role in automated monitoring systems. Most previous deep learning efforts related to time series anomaly detection were based on recurrent neural networks (RNN). In this paper, we propose a time series segmentation approach based on convolutional neural networks (CNN) for anomaly detection. Moreover, we propose a transfer learning framework that pretrains a model on a large-scale synthetic univariate time series data set and then fine-tunes its weights on small-scale, univariate or multivariate data sets with previously unseen classes of anomalies. For the multivariate case, we introduce a novel network architecture. The approach was tested on multiple synthetic and real data sets successfully.},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Wen, Tailai and Keyes, Roy},
	month = may,
	year = {2019},
	note = {arXiv:1905.13628 [cs, stat]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 8 pages, 8 figures, AI for Internet of Things Workshop in IJCAI 2019},
	file = {arXiv.org Snapshot:/home/gurp/Zotero/storage/LNHQ9C8X/1905.html:text/html;TSAnomalyDetectionCNNWenKeyes.pdf:/home/gurp/Zotero/storage/NB3WN4PN/1905.13628.pdf:application/pdf},
}

@misc{zeiler_visualizing_2013,
	title = {Visualizing and {Understanding} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1311.2901},
	abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky {\textbackslash}etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
	urldate = {2023-09-25},
	publisher = {arXiv},
	author = {Zeiler, Matthew D. and Fergus, Rob},
	month = nov,
	year = {2013},
	note = {arXiv:1311.2901 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:/home/gurp/Zotero/storage/MP94L6TG/1311.html:text/html;Full Text PDF:/home/gurp/Zotero/storage/M5UNTP3R/Zeiler and Fergus - 2013 - Visualizing and Understanding Convolutional Networ.pdf:application/pdf},
}

@misc{maxfield_synthetic_2023,
	title = {Synthetic data: breaking the data logjam in machine learning for healthcare // van der {Schaar} {Lab}},
	shorttitle = {Synthetic data},
	url = {https://www.vanderschaar-lab.com/synthetic-data-breaking-the-data-logjam-in-machine-learning-for-healthcare/},
	abstract = {Synthetic data could help transform healthcare by revolutionizing how we access and interact with datasets, while maintaining patient privacy.},
	urldate = {2023-09-25},
	author = {Maxfield, Zhaozhi Qian, Boris van Breugel, Nick, Mihaela van der Schaar},
	month = feb,
	year = {2023},
}

@misc{dau_ucr_2019,
	title = {The {UCR} {Time} {Series} {Archive}},
	url = {http://arxiv.org/abs/1810.07758},
	abstract = {The UCR Time Series Archive - introduced in 2002, has become an important resource in the time series data mining community, with at least one thousand published papers making use of at least one data set from the archive. The original incarnation of the archive had sixteen data sets but since that time, it has gone through periodic expansions. The last expansion took place in the summer of 2015 when the archive grew from 45 to 85 data sets. This paper introduces and will focus on the new data expansion from 85 to 128 data sets. Beyond expanding this valuable resource, this paper offers pragmatic advice to anyone who may wish to evaluate a new algorithm on the archive. Finally, this paper makes a novel and yet actionable claim: of the hundreds of papers that show an improvement over the standard baseline (1-nearest neighbor classification), a large fraction may be mis-attributing the reasons for their improvement. Moreover, they may have been able to achieve the same improvement with a much simpler modification, requiring just a single line of code.},
	urldate = {2023-09-26},
	publisher = {arXiv},
	author = {Dau, Hoang Anh and Bagnall, Anthony and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Keogh, Eamonn},
	month = sep,
	year = {2019},
	note = {arXiv:1810.07758 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/gurp/Zotero/storage/DVUFAS4N/1810.html:text/html;Full Text PDF:/home/gurp/Zotero/storage/GD7LGSKM/Dau et al. - 2019 - The UCR Time Series Archive.pdf:application/pdf},
}


@inproceedings{crabbe_explaining_2021,
	title = {Explaining {Latent} {Representations} with a {Corpus} of {Examples}},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper_files/paper/2021/hash/65658fde58ab3c2b6e5132a39fae7cb9-Abstract.html},
	abstract = {Modern machine learning models are complicated. Most of them rely on convoluted latent representations of their input to issue a prediction. To achieve greater transparency than a black-box that connects inputs to predictions, it is necessary to gain a deeper understanding of these latent representations. To that aim, we propose SimplEx: a user-centred method that provides example-based explanations with reference to a freely selected set of examples, called the corpus. SimplEx uses the corpus to improve the user’s understanding of the latent space with post-hoc explanations answering two questions: (1) Which corpus examples explain the prediction issued for a given test example? (2) What features of these corpus examples are relevant for the model to relate them to the test example? SimplEx provides an answer by reconstructing the test latent representation as a mixture of corpus latent representations. Further, we propose a novel approach, the integrated Jacobian, that allows SimplEx to make explicit the contribution of each corpus feature in the mixture. Through experiments on tasks ranging from mortality prediction to image classification, we demonstrate that these decompositions are robust and accurate. With illustrative use cases in medicine, we show that SimplEx empowers the user by highlighting relevant patterns in the corpus that explain model representations. Moreover, we demonstrate how the freedom in choosing the corpus allows the user to have personalized explanations in terms of examples that are meaningful for them.},
	urldate = {2023-09-27},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Crabbe, Jonathan and Qian, Zhaozhi and Imrie, Fergus and van der Schaar, Mihaela},
	year = {2021},
	pages = {12154--12166},
	file = {Full Text PDF:/home/gurp/Zotero/storage/TP6BEFXB/Crabbe et al. - 2021 - Explaining Latent Representations with a Corpus of.pdf:application/pdf},
}



@article{ding_model_2018,
	title = {Model {Selection} {Techniques}: {An} {Overview}},
	volume = {35},
	issn = {1558-0792},
	shorttitle = {Model {Selection} {Techniques}},
	url = {https://ieeexplore.ieee.org/abstract/document/8498082},
	doi = {10.1109/MSP.2018.2867638},
	abstract = {In the era of big data, analysts usually explore various statistical models or machine-learning methods for observed data to facilitate scientific discoveries or gain predictive power. Whatever data and fitting procedures are employed, a crucial step is to select the most appropriate model or method from a set of candidates. Model selection is a key ingredient in data analysis for reliable and reproducible statistical inference or prediction, and thus it is central to scientific studies in such fields as ecology, economics, engineering, finance, political science, biology, and epidemiology. There has been a long history of model selection techniques that arise from researches in statistics, information theory, and signal processing. A considerable number of methods has been proposed, following different philosophies and exhibiting varying performances. The purpose of this article is to provide a comprehensive overview of them, in terms of their motivation, large sample performance, and applicability. We provide integrated and practically relevant discussions on theoretical properties of state-of-the-art model selection approaches. We also share our thoughts on some controversial views on the practice of model selection.},
	number = {6},
	urldate = {2023-11-17},
	journal = {IEEE Signal Processing Magazine},
	author = {Ding, Jie and Tarokh, Vahid and Yang, Yuhong},
	month = nov,
	year = {2018},
	note = {Conference Name: IEEE Signal Processing Magazine},
	pages = {16--34},
	file = {IEEE Xplore Abstract Record:/home/gurp/Zotero/storage/IPDJAH6G/8498082.html:text/html;Submitted Version:/home/gurp/Zotero/storage/TGU6GRQ2/Ding et al. - 2018 - Model Selection Techniques An Overview.pdf:application/pdf},
}

@misc{raschka_model_2020,
	title = {Model {Evaluation}, {Model} {Selection}, and {Algorithm} {Selection} in {Machine} {Learning}},
	url = {http://arxiv.org/abs/1811.12808},
	doi = {10.48550/arXiv.1811.12808},
	abstract = {The correct use of model evaluation, model selection, and algorithm selection techniques is vital in academic machine learning research as well as in many industrial settings. This article reviews different techniques that can be used for each of these three subtasks and discusses the main advantages and disadvantages of each technique with references to theoretical and empirical studies. Further, recommendations are given to encourage best yet feasible practices in research and applications of machine learning. Common methods such as the holdout method for model evaluation and selection are covered, which are not recommended when working with small datasets. Different flavors of the bootstrap technique are introduced for estimating the uncertainty of performance estimates, as an alternative to confidence intervals via normal approximation if bootstrapping is computationally feasible. Common cross-validation techniques such as leave-one-out cross-validation and k-fold cross-validation are reviewed, the bias-variance trade-off for choosing k is discussed, and practical tips for the optimal choice of k are given based on empirical evidence. Different statistical tests for algorithm comparisons are presented, and strategies for dealing with multiple comparisons such as omnibus tests and multiple-comparison corrections are discussed. Finally, alternative methods for algorithm selection, such as the combined F-test 5x2 cross-validation and nested cross-validation, are recommended for comparing machine learning algorithms when datasets are small.},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Raschka, Sebastian},
	month = nov,
	year = {2020},
	note = {arXiv:1811.12808 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: v3 (Nov 2020): Fixes SD from pooled proportions in Sec 4.2 Fixes exact binomial p-value in Sec 4.4 by using max(B, C) instead of B in the sum. Fixes typo using wrong symbols in Looney's F-test's SSA in Sec 4.7},
	file = {arXiv Fulltext PDF:/home/gurp/Zotero/storage/6MLFNWYL/Raschka - 2020 - Model Evaluation, Model Selection, and Algorithm S.pdf:application/pdf;arXiv.org Snapshot:/home/gurp/Zotero/storage/6CQ6K27J/1811.html:text/html},
}


@article{linusson_nonconformity_2021,
	title = {Nonconformity {Measures} and {Ensemble} {Strategies} : {An} {Analysis} of {Conformal} {Predictor} {Efficiency} and {Validity}},
	shorttitle = {Nonconformity {Measures} and {Ensemble} {Strategies}},
	url = {https://urn.kb.se/resolve?urn=urn:nbn:se:su:diva-192613},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {eng},
	urldate = {2023-11-12},
	author = {Linusson, Henrik},
	year = {2021},
	file = {Linusson - 2021 - Nonconformity Measures and Ensemble Strategies  An Analysis of Conformal Predictor Efficiency and Validity.pdf:/home/gurp/Zotero/storage/U8SLYC2R/Linusson - 2021 - Nonconformity Measures and Ensemble Strategies  An Analysis of Conformal Predictor Efficiency and Validity.pdf:application/pdf},
}

@misc{papernot_deep_2018,
	title = {Deep k-{Nearest} {Neighbors}: {Towards} {Confident}, {Interpretable} and {Robust} {Deep} {Learning}},
	shorttitle = {Deep k-{Nearest} {Neighbors}},
	url = {http://arxiv.org/abs/1803.04765},
	doi = {10.48550/arXiv.1803.04765},
	abstract = {Deep neural networks (DNNs) enable innovative applications of machine learning like image recognition, machine translation, or malware detection. However, deep learning is often criticized for its lack of robustness in adversarial settings (e.g., vulnerability to adversarial inputs) and general inability to rationalize its predictions. In this work, we exploit the structure of deep learning to enable new learning-based inference and decision strategies that achieve desirable properties such as robustness and interpretability. We take a first step in this direction and introduce the Deep k-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest neighbors algorithm with representations of the data learned by each layer of the DNN: a test input is compared to its neighboring training points according to the distance that separates them in the representations. We show the labels of these neighboring points afford confidence estimates for inputs outside the model's training manifold, including on malicious inputs like adversarial examples--and therein provides protections against inputs that are outside the models understanding. This is because the nearest neighbors can be used to estimate the nonconformity of, i.e., the lack of support for, a prediction in the training data. The neighbors also constitute human-interpretable explanations of predictions. We evaluate the DkNN algorithm on several datasets, and show the confidence estimates accurately identify inputs outside the model, and that the explanations provided by nearest neighbors are intuitive and useful in understanding model failures.},
	urldate = {2023-11-12},
	author = {Papernot, Nicolas and McDaniel, Patrick},
	month = mar,
	year = {2018},
	note = {arXiv:1803.04765 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Papernot and McDaniel - 2018 - Deep k-Nearest Neighbors Towards Confident, Interpretable and Robust Deep Learning.pdf:/home/gurp/Zotero/storage/ULN892BV/Papernot and McDaniel - 2018 - Deep k-Nearest Neighbors Towards Confident, Interpretable and Robust Deep Learning.pdf:application/pdf},
}

@misc{kim_interpretability_2018,
	title = {Interpretability {Beyond} {Feature} {Attribution}: {Quantitative} {Testing} with {Concept} {Activation} {Vectors} ({TCAV})},
	shorttitle = {Interpretability {Beyond} {Feature} {Attribution}},
	url = {http://arxiv.org/abs/1711.11279},
	doi = {10.48550/arXiv.1711.11279},
	abstract = {The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net's internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result--for example, how sensitive a prediction of "zebra" is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.},
	urldate = {2023-11-12},
	author = {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and Sayres, Rory},
	month = jun,
	year = {2018},
	note = {arXiv:1711.11279 [stat]},
	keywords = {Statistics - Machine Learning},
	file = {Kim et al. - 2018 - Interpretability Beyond Feature Attribution Quantitative Testing with Concept Activation Vectors (TCAV).pdf:/home/gurp/Zotero/storage/VINXM3NZ/Kim et al. - 2018 - Interpretability Beyond Feature Attribution Quantitative Testing with Concept Activation Vectors (TCAV).pdf:application/pdf},
}

@inproceedings{rechkemmer_when_2022,
	address = {New York, NY, USA},
	series = {{CHI} '22},
	title = {When {Confidence} {Meets} {Accuracy}: {Exploring} the {Effects} of {Multiple} {Performance} {Indicators} on {Trust} in {Machine} {Learning} {Models}},
	isbn = {978-1-4503-9157-3},
	shorttitle = {When {Confidence} {Meets} {Accuracy}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3501967},
	doi = {10.1145/3491102.3501967},
	abstract = {Previous research shows that laypeople’s trust in a machine learning model can be affected by both performance measurements of the model on the aggregate level and performance estimates on individual predictions. However, it is unclear how people would trust the model when multiple performance indicators are presented at the same time. We conduct an exploratory human-subject experiment to answer this question. We find that while the level of model confidence significantly affects people’s belief in model accuracy, both the model’s stated and observed accuracy generally have a larger impact on people’s willingness to follow the model’s predictions as well as their self-reported levels of trust in the model, especially after observing the model’s performance in practice. We hope the empirical evidence reported in this work could open doors to further studies to advance understanding of how people perceive, process, and react to performance-related information of machine learning.},
	urldate = {2023-11-16},
	publisher = {Association for Computing Machinery},
	author = {Rechkemmer, Amy and Yin, Ming},
	month = apr,
	year = {2022},
	keywords = {accuracy, confidence, human-subject experiments, Machine learning, trust},
	pages = {1--14},
	file = {Rechkemmer and Yin - 2022 - When Confidence Meets Accuracy Exploring the Effects of Multiple Performance Indicators on Trust in Machine Learning Models.pdf:/home/gurp/Zotero/storage/FHMG9IPU/Rechkemmer and Yin - 2022 - When Confidence Meets Accuracy Exploring the Effects of Multiple Performance Indicators on Trust in Machine Learning Models.pdf:application/pdf},
}

@inproceedings{poggi_quantitative_2017,
	title = {Quantitative {Evaluation} of {Confidence} {Measures} in a {Machine} {Learning} {World}},
	url = {https://openaccess.thecvf.com/content_iccv_2017/html/Poggi_Quantitative_Evaluation_of_ICCV_2017_paper.html},
	urldate = {2023-11-16},
	author = {Poggi, Matteo and Tosi, Fabio and Mattoccia, Stefano},
	year = {2017},
	pages = {5228--5237},
	file = {Poggi et al. - 2017 - Quantitative Evaluation of Confidence Measures in a Machine Learning World.pdf:/home/gurp/Zotero/storage/K935LV8Z/Poggi et al. - 2017 - Quantitative Evaluation of Confidence Measures in a Machine Learning World.pdf:application/pdf},
}


@misc{harvey_multiple_2013,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Multiple {Testing} in {Economics}},
	url = {https://papers.ssrn.com/abstract=2358214},
	doi = {10.2139/ssrn.2358214},
	abstract = {We propose a new way to conduct multiple hypothesis testing in economics research. Our framework allows for correlation among tests and incomplete data, both of which are prevalent in economic meta-analysis. Our simulations show that that our method is able to produce the correct p-value cutoff that controls the overall rate of false discoveries at a prespecified level of significance. The single hypothesis test, as used by most researchers, leads to too many false discoveries and should be avoided.},
	language = {en},
	urldate = {2023-11-17},
	author = {Harvey, Campbell R. and Liu, Yan},
	month = nov,
	year = {2013},
	keywords = {Correlation, Data mining, False discoveries, Incomplete data, Meta-analysis, Multiple tests, Type I error, Type II error},
	file = {Full Text PDF:/home/gurp/Zotero/storage/F8ZV4W3M/Harvey and Liu - 2013 - Multiple Testing in Economics.pdf:application/pdf},
}

@article{deng2012mnist,
  title={The mnist database of handwritten digit images for machine learning research},
  author={Deng, Li},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}


@misc{jaeger_two_2014,
	title = {Two public chest {X}-ray datasets for computer-aided screening of pulmonary diseases - {PMC}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4256233/},
	urldate = {2023-11-17},
	author = {Jaeger, Stefan and Candemir, Sema and Antani, Sameer and Wang, Yi-Xiang and Lu, Pu-Xuan and Thoma, George},
	year = {2014},
	file = {Two public chest X-ray datasets for computer-aided screening of pulmonary diseases - PMC:/home/gurp/Zotero/storage/ZGGZZAP9/PMC4256233.html:text/html},
}


@article{borkowski_lung_colon,
title= {LC25000 Lung and colon histopathological image dataset},
keywords= {cancer,histopathology},
author= {Andrew A. Borkowski, Marilyn M. Bui, L. Brannon Thomas, Catherine P. Wilson, Lauren A. DeLand, Stephen M. Mastorides},
url= {https://github.com/tampapath/lung_colon_image_set}
}



@misc{zha_data-centric_2023,
	title = {Data-centric {Artificial} {Intelligence}: {A} {Survey}},
	shorttitle = {Data-centric {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/2303.10158},
	doi = {10.48550/arXiv.2303.10158},
	abstract = {Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI. The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages of the data lifecycle. We hope it can help the readers efficiently grasp a broad picture of this field, and equip them with the techniques and further research ideas to systematically engineer data for building AI systems. A companion list of data-centric AI resources will be regularly updated on https://github.com/daochenzha/data-centric-AI},
	urldate = {2023-11-21},
	author = {Zha, Daochen and Bhat, Zaid Pervaiz and Lai, Kwei-Herng and Yang, Fan and Jiang, Zhimeng and Zhong, Shaochen and Hu, Xia},
	month = jun,
	year = {2023},
	note = {arXiv:2303.10158 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Databases},
	file = {Zha et al. - 2023 - Data-centric Artificial Intelligence A Survey.pdf:/home/gurp/Zotero/storage/PJGLA4FM/Zha et al. - 2023 - Data-centric Artificial Intelligence A Survey.pdf:application/pdf},
}
