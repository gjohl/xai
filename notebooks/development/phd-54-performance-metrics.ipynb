{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af4ae91-0c73-4eaf-8d2a-b583eef164b9",
   "metadata": {},
   "source": [
    "# Computing performance evaluation metrics\n",
    "Get some model predictions that we can then compute performance metrics for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f8b8e0-c72b-4121-a9dd-bb75ec435bcd",
   "metadata": {},
   "source": [
    "## 1. Load a trained model\n",
    "To save time we will load a previously trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4986a2-8801-4eac-b49f-a0615097c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xai.models.simple_cnn import CNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f01faa-2bf5-4235-b64d-cb45a07ab8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55f3f203-7c80-4bb6-be00-52771a6afc96",
   "metadata": {},
   "source": [
    "## 2. Get model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d5030-c3ef-48e1-b4f4-279c358058b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c19628-34d3-4063-8d83-8d87455d7ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25642cb-af6a-4f40-9af3-2bfdbd8ab0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee0963-caac-4bb8-a002-b994638fe94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c35c77c6-65f8-400b-9bf7-632f90467452",
   "metadata": {},
   "source": [
    "## 3. Calculate performance metrics\n",
    "- accuracy\n",
    "- auc\n",
    "- f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd70a68-badd-44e6-858e-765214872124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17291197-a41a-4bba-84f3-cc9177e54660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be08ebf-4627-4138-9272-fe1ef4f4f7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329b337d-4f38-40e0-b3f9-52d92b7926ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Accuracy classification score.\n",
       "\n",
       "In multilabel classification, this function computes subset accuracy:\n",
       "the set of labels predicted for a sample must *exactly* match the\n",
       "corresponding set of labels in y_true.\n",
       "\n",
       "Read more in the :ref:`User Guide <accuracy_score>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "y_true : 1d array-like, or label indicator array / sparse matrix\n",
       "    Ground truth (correct) labels.\n",
       "\n",
       "y_pred : 1d array-like, or label indicator array / sparse matrix\n",
       "    Predicted labels, as returned by a classifier.\n",
       "\n",
       "normalize : bool, default=True\n",
       "    If ``False``, return the number of correctly classified samples.\n",
       "    Otherwise, return the fraction of correctly classified samples.\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "score : float\n",
       "    If ``normalize == True``, return the fraction of correctly\n",
       "    classified samples (float), else returns the number of correctly\n",
       "    classified samples (int).\n",
       "\n",
       "    The best performance is 1 with ``normalize == True`` and the number\n",
       "    of samples with ``normalize == False``.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "balanced_accuracy_score : Compute the balanced accuracy to deal with\n",
       "    imbalanced datasets.\n",
       "jaccard_score : Compute the Jaccard similarity coefficient score.\n",
       "hamming_loss : Compute the average Hamming loss or Hamming distance between\n",
       "    two sets of samples.\n",
       "zero_one_loss : Compute the Zero-one classification loss. By default, the\n",
       "    function will return the percentage of imperfectly predicted subsets.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "In binary classification, this function is equal to the `jaccard_score`\n",
       "function.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.metrics import accuracy_score\n",
       ">>> y_pred = [0, 2, 1, 3]\n",
       ">>> y_true = [0, 1, 2, 3]\n",
       ">>> accuracy_score(y_true, y_pred)\n",
       "0.5\n",
       ">>> accuracy_score(y_true, y_pred, normalize=False)\n",
       "2\n",
       "\n",
       "In the multilabel case with binary label indicators:\n",
       "\n",
       ">>> import numpy as np\n",
       ">>> accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n",
       "0.5\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/xai/lib/python3.11/site-packages/sklearn/metrics/_classification.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae2406-5e97-4f95-a655-02032449b7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
